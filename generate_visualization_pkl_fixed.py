#!/usr/bin/env python3
"""
GMAP í†µí•© ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì˜ˆì¸¡ ê¶¤ì ì„ ìƒì„±í•˜ê³  
ê·¸ë£¹ í• ë‹¹ ì •ë³´ë¥¼ í¬í•¨í•œ ì‹œê°í™”ìš© PKL íŒŒì¼ì„ ìƒì„±í•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸ (ìˆ˜ì • ë²„ì „)

train_unified.pyì˜ êµ¬ì¡°ë¥¼ ë”°ë¼ì„œ ì‘ì„±í•¨
"""

import os
import pickle
import argparse
import torch
import numpy as np
from tqdm import tqdm
from torch.utils.data import DataLoader
import pandas as pd

# Import unified model and utilities
from model.dmrgcn_gpgraph import DMRGCN_GPGraph_Model
from datasets.dataloader import TrajectoryDataset, collate_fn


def parse_args():
    """Parse command line arguments"""
    parser = argparse.ArgumentParser(description='Generate Visualization PKL from GMAP Model')
    
    # Model and data parameters
    parser.add_argument('--dataset', default='hotel', 
                       choices=['eth', 'hotel', 'univ', 'zara1', 'zara2'],
                       help='Dataset name')
    parser.add_argument('--checkpoint', default='./server_exp-hotel/hotel_best.pth',
                       help='Path to model checkpoint')
    
    # Output parameters
    parser.add_argument('--output_dir', default='../ETH-UCY-Trajectory-Visualizer/pred_traj_dump/',
                       help='Output directory for PKL files')
    parser.add_argument('--output_name', default='GMAP_{}.pkl',
                       help='Output PKL filename pattern')
    
    # Prediction parameters
    parser.add_argument('--batch_size', type=int, default=1, 
                       help='Batch size (keep as 1 for simplicity)')
    parser.add_argument('--max_sequences', type=int, default=50, 
                       help='Maximum number of sequences to process (-1 for all)')
    
    return parser.parse_args()


def load_model_and_args(checkpoint_path, device):
    """Load model and arguments from checkpoint - train_unified.py ìŠ¤íƒ€ì¼"""
    print(f"ğŸ“‚ Loading checkpoint from {checkpoint_path}")
    checkpoint = torch.load(checkpoint_path, map_location=device)
    args = checkpoint['args']
    
    print(f"ğŸ”§ Model configuration:")
    print(f"   Dataset: {args.dataset}")
    print(f"   Obs/Pred length: {args.obs_len}/{args.pred_len}")
    print(f"   Group type: {args.group_type}")
    print(f"   Group threshold: {args.group_threshold}")
    
    # Create model with same configuration as training
    model = DMRGCN_GPGraph_Model(
        d_in=args.d_in,
        d_h=args.d_h,
        d_gp_in=args.d_gp_in,
        T_pred=args.pred_len,
        output_dim=2,
        dmrgcn_hidden_dims=args.dmrgcn_hidden_dims,
        dmrgcn_kernel_size=tuple(args.kernel_size),
        dmrgcn_dropout=args.dropout,
        distance_scales=args.distance_scales,
        agg_method=args.agg_method,
        group_type=args.group_type,
        group_threshold=args.group_threshold,
        mix_type=args.mix_type,
        enable_paths={
            'agent': args.enable_agent,
            'intra': args.enable_intra,
            'inter': args.enable_inter
        },
        use_multimodal=args.use_multimodal,
        use_simple_head=args.use_simple_head
    )
    
    model.load_state_dict(checkpoint['model_state_dict'])
    model = model.to(device)
    model.eval()
    
    print(f"âœ… Model loaded successfully")
    return model, args


def convert_batch_to_unified_format(batch, device, args):
    """Convert batch to unified format - train_unified.pyì™€ ë™ì¼"""
    (obs_traj, pred_traj, obs_traj_rel, pred_traj_rel,
     non_linear_ped, loss_mask, V_obs, A_obs, V_pred, A_pred,
     seq_start_end, agent_ids) = batch
    
    # Move to device
    obs_traj = obs_traj.to(device).float()
    pred_traj = pred_traj.to(device).float()
    obs_traj_rel = obs_traj_rel.to(device).float()
    pred_traj_rel = pred_traj_rel.to(device).float()
    V_obs = V_obs.to(device).float()
    A_obs = A_obs.to(device).float()
    loss_mask = loss_mask.to(device).float()
    
    # Get dimensions
    T_obs, N = obs_traj.shape[:2]
    T_pred = pred_traj.shape[0]
    B = 1  # Single sequence per batch
    
    # Construct input features X_obs: [B, T_obs, N, d_in]
    if args.use_multimodal and args.d_in >= 4:
        # Use both positions and velocities
        X_obs = torch.cat([
            obs_traj.unsqueeze(0),      # [1, T_obs, N, 2] positions
            obs_traj_rel.unsqueeze(0)   # [1, T_obs, N, 2] velocities
        ], dim=-1)  # [B, T_obs, N, 4]
    else:
        # Use relative displacements only
        X_obs = obs_traj_rel.unsqueeze(0)  # [B, T_obs, N, 2]
    
    # Construct adjacency A_obs: [B, T_obs, N, N]
    A_obs_unified = A_obs[:, 1, :, :, :].permute(0, 1, 2, 3)  # [B, T_obs, N, N]
    
    # Construct masks
    M_obs = loss_mask[:T_obs].unsqueeze(0)  # [B, T_obs, N]
    M_pred = loss_mask[T_obs:].unsqueeze(0)  # [B, T_pred, N]
    
    # Return data for prediction and visualization
    return X_obs, A_obs_unified, M_obs, M_pred, obs_traj, pred_traj_rel, loss_mask


def extract_group_assignments(model, X_obs, A_obs, M_obs, args):
    """Extract group assignments from the model"""
    try:
        # GP-Graph ëª¨ë¸ì—ì„œ ê·¸ë£¹ ì •ë³´ ì¶”ì¶œ ì‹œë„
        if hasattr(model, 'gpgraph_head'):
            # GP-Graph í—¤ë“œì—ì„œ ê·¸ë£¹ ì •ë³´ë¥¼ ì–»ê¸° ìœ„í•´ forward pass ì‹¤í–‰
            with torch.no_grad():
                _ = model(X_obs, A_obs, M_obs)
                
                # ê·¸ë£¹ í• ë‹¹ ì •ë³´ ì¶”ì¶œ
                if hasattr(model.gpgraph_head, 'group_assignments'):
                    group_assignments = model.gpgraph_head.group_assignments
                    return group_assignments.cpu().numpy()
        
        # ê¸°ë³¸ ê·¸ë£¹ í• ë‹¹: Euclidean distance ê¸°ë°˜
        N = X_obs.shape[2]
        last_positions = X_obs[0, -1, :, :2].cpu().numpy()  # [N, 2] - ë§ˆì§€ë§‰ ê´€ì°° ìœ„ì¹˜
        
        # ê°„ë‹¨í•œ í´ëŸ¬ìŠ¤í„°ë§ (ê±°ë¦¬ ê¸°ë°˜)
        groups = []
        group_id = 0
        assigned = set()
        
        for i in range(N):
            if i in assigned:
                continue
                
            current_group = [i]
            assigned.add(i)
            
            for j in range(i+1, N):
                if j in assigned:
                    continue
                    
                dist = np.linalg.norm(last_positions[i] - last_positions[j])
                if dist < args.group_threshold:
                    current_group.append(j)
                    assigned.add(j)
            
            # ê·¸ë£¹ í• ë‹¹
            for agent_idx in current_group:
                groups.append((agent_idx, group_id))
            
            group_id += 1
        
        # ì •ë ¬í•´ì„œ agent_idë³„ ê·¸ë£¹ ë°˜í™˜
        groups.sort(key=lambda x: x[0])
        group_assignments = np.array([g[1] for g in groups])
        
        return group_assignments
        
    except Exception as e:
        print(f"âš ï¸  Warning: Could not extract group assignments: {e}")
        N = X_obs.shape[2]
        return np.zeros(N, dtype=int)  # ëª¨ë“  ì—ì´ì „íŠ¸ë¥¼ ê·¸ë£¹ 0ìœ¼ë¡œ ì„¤ì •


def predict_trajectories(model, test_loader, device, train_args, max_sequences):
    """Generate predictions for test sequences"""
    print(f"ğŸš€ Generating predictions for {train_args.dataset} dataset...")
    
    all_predictions = []
    all_groups = []
    all_obs_traj = []
    all_pred_traj_gt = []
    all_metadata = []
    
    with torch.no_grad():
        pbar = tqdm(test_loader, desc='Predicting trajectories')
        
        for batch_idx, batch in enumerate(pbar):
            if max_sequences > 0 and batch_idx >= max_sequences:
                break
                
            try:
                # Convert to unified format
                X_obs, A_obs, M_obs, M_pred, obs_traj, pred_traj_rel, loss_mask = convert_batch_to_unified_format(
                    batch, device, train_args
                )
                
                # Forward pass to get predictions
                delta_Y_pred = model(X_obs, A_obs, M_obs, M_pred=M_pred)
                
                # Extract group assignments
                group_assignments = extract_group_assignments(model, X_obs, A_obs, M_obs, train_args)
                
                # Convert predictions to absolute coordinates
                obs_abs = obs_traj.cpu().numpy()  # [T_obs, N, 2]
                pred_rel = delta_Y_pred.squeeze(0).cpu().numpy()  # [T_pred, N, 2]
                pred_gt_rel = pred_traj_rel.cpu().numpy()  # [T_pred, N, 2]
                mask = loss_mask.cpu().numpy()  # [T_obs + T_pred, N]
                
                # ë§ˆì§€ë§‰ ê´€ì°° ìœ„ì¹˜ì—ì„œ ì‹œì‘í•´ì„œ ëˆ„ì  í•©ìœ¼ë¡œ ì ˆëŒ€ ì¢Œí‘œ ê³„ì‚°
                last_obs = obs_abs[-1:, :, :]  # [1, N, 2]
                pred_abs = np.cumsum(pred_rel, axis=0) + last_obs  # [T_pred, N, 2]
                pred_gt_abs = np.cumsum(pred_gt_rel, axis=0) + last_obs  # [T_pred, N, 2]
                
                # ìœ íš¨í•œ ì—ì´ì „íŠ¸ë§Œ ì„ íƒ (mask ê¸°ë°˜)
                valid_agents = mask[-1, :] > 0  # ë§ˆì§€ë§‰ ì‹œì ì—ì„œ ìœ íš¨í•œ ì—ì´ì „íŠ¸
                N_valid = valid_agents.sum()
                
                if N_valid > 0:
                    # ì‹œí€€ìŠ¤ë³„ ë°ì´í„° ì €ì¥ (ê° ì—ì´ì „íŠ¸ë³„ë¡œ)
                    seq_predictions = []
                    seq_groups = []
                    
                    for agent_idx in range(len(valid_agents)):
                        if valid_agents[agent_idx]:
                            seq_predictions.append(pred_abs[:, agent_idx, :])  # [T_pred, 2]
                            seq_groups.append(group_assignments[agent_idx])
                    
                    all_predictions.append(seq_predictions)
                    all_groups.append(np.array(seq_groups))
                    all_obs_traj.append(obs_abs[:, valid_agents, :])  # [T_obs, N_valid, 2]
                    all_pred_traj_gt.append(pred_gt_abs[:, valid_agents, :])  # [T_pred, N_valid, 2]
                    
                    all_metadata.append({
                        'seq_idx': batch_idx,
                        'num_agents': int(N_valid),
                        'pred_length': train_args.pred_len
                    })
                    
                    pbar.set_postfix({
                        'Seq': batch_idx,
                        'Agents': int(N_valid),
                        'Groups': len(np.unique(seq_groups))
                    })
                
            except Exception as e:
                print(f"âš ï¸  Error processing batch {batch_idx}: {e}")
                continue
    
    print(f"âœ… Generated {len(all_predictions)} sequences with predictions")
    return all_predictions, all_groups, all_obs_traj, all_pred_traj_gt, all_metadata


def main():
    """Main function"""
    args = parse_args()
    
    # Device setup
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"ğŸ”§ Using device: {device}")
    
    # Load model
    model, train_args = load_model_and_args(args.checkpoint, device)
    
    # Setup dataset - use test directory
    dataset_path = f'./datasets/{args.dataset}/test/'
    print(f"ğŸ“ Loading dataset from {dataset_path}")
    
    test_dataset = TrajectoryDataset(
        dataset_path,
        obs_len=train_args.obs_len,
        pred_len=train_args.pred_len,
        skip=train_args.skip,
        min_ped=train_args.min_ped,
        use_cache=train_args.use_cache,
        cache_dir=train_args.cache_dir
    )
    
    test_loader = DataLoader(
        test_dataset,
        batch_size=args.batch_size,
        shuffle=False,
        collate_fn=collate_fn
    )
    
    print(f"ğŸ“Š Test dataset: {len(test_dataset)} sequences")
    
    # Generate predictions
    predictions, groups, obs_traj, pred_traj_gt, metadata = predict_trajectories(
        model, test_loader, device, train_args, args.max_sequences
    )
    
    # Create visualization data structure
    visualization_data = {
        'predictions': predictions,
        'groups': groups,
        'obs_traj': obs_traj,
        'pred_traj_gt': pred_traj_gt,
        'metadata': metadata,
        'dataset': args.dataset,
        'model_info': {
            'model_type': 'GMAP_unified',
            'group_type': train_args.group_type,
            'group_threshold': train_args.group_threshold,
            'obs_len': train_args.obs_len,
            'pred_len': train_args.pred_len
        }
    }
    
    # Save PKL file
    os.makedirs(args.output_dir, exist_ok=True)
    output_path = os.path.join(args.output_dir, args.output_name.format(args.dataset))
    
    with open(output_path, 'wb') as f:
        pickle.dump(visualization_data, f)
    
    total_agents = sum(len(seq) for seq in predictions)
    print(f"ğŸ‰ Visualization PKL saved: {output_path}")
    print(f"   Sequences: {len(predictions)}")
    print(f"   Total agents: {total_agents}")
    print(f"   Groups: {len(set().union(*groups)) if groups else 0}")


if __name__ == '__main__':
    main()